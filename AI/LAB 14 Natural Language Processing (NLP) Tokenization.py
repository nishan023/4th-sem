import nltk
from nltk.tokenize import word_tokenize

sentence = "Artificial intelligence is the future."
tokens = word_tokenize(sentence)
print(tokens)
